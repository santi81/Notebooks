{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S/4HANA ML Class\n",
    "### Linear Models / Bias and Variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "np.random.seed(0)\n",
    "X, y = make_circles(n_samples=1000, factor=.3, noise=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "logReg = linear_model.LogisticRegression(solver='lbfgs')\n",
    "logReg.fit(X_train, y_train)\n",
    "\n",
    "yhat = logReg.predict(X_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svc = svm.SVC(gamma='auto')\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "yhat = svc.predict(X_test)\n",
    "mean_squared_error(y_test, yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot\n",
    "plt.figure()\n",
    "plt.title(\"Raw Data\")\n",
    "blueSet = y == 0\n",
    "orangeSet = y == 1\n",
    "\n",
    "plt.scatter(X[blueSet, 0], X[blueSet, 1], c=\"blue\",\n",
    "            s=20, edgecolor='k')\n",
    "plt.scatter(X[orangeSet, 0], X[orangeSet, 1], c=\"orange\",\n",
    "            s=20, edgecolor='k')\n",
    "plt.xlabel(\"$x_1$\")\n",
    "plt.ylabel(\"$x_2$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Decision Boundary\n",
    "\n",
    "\n",
    "w = logReg.coef_[0]\n",
    "b = logReg.intercept_\n",
    "# w[1] * y = w[0] * x + b # solve for y\n",
    "# y = (w[0] * x)/w[1] + b / w[1]\n",
    "# Use smallest and largest x values\n",
    "\n",
    "y_boundary = [-1 * (w[0] * X[:,0].min() + b) / w[1],\n",
    "              -1 * (w[0] * X[:,0].max() + b) / w[1]]\n",
    "                 \n",
    "# plt.plot([X.min(), X.max()], y_boundary, 'r-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of raw data + LR decision boundary\n",
    "plt.figure()\n",
    "plt.title(\"Raw Data\")\n",
    "blueSet = y == 0\n",
    "orangeSet = y == 1\n",
    "\n",
    "plt.scatter(X[blueSet, 0], X[blueSet, 1], c=\"blue\",\n",
    "            s=20, edgecolor='k')\n",
    "plt.scatter(X[orangeSet, 0], X[orangeSet, 1], c=\"orange\",\n",
    "            s=20, edgecolor='k')\n",
    "plt.xlabel(\"$x_1$\")\n",
    "plt.ylabel(\"$x_2$\")\n",
    "# Print Decision Boundary\n",
    "plt.ylim(X[:,1].min(), X[:,1].max())\n",
    "plt.plot([X[:,0].min(), X[:,0].max()], y_boundary, 'r-')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blue = 0\n",
    "# orange = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some predictions...\n",
    "logReg.predict(np.array([[0, -1]]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg.predict(np.array([[1, 10]]))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generic Solution for Plotting Decision Boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grid \n",
    "\n",
    "gridXs, gridYs = np.mgrid[X[:, 0].min():X[:, 0].max():.1, X[:,1].min():X[:,1].max():.1]\n",
    "gridXs = gridXs.ravel()\n",
    "gridYs = gridYs.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_predict(k):\n",
    "    return logReg.predict(k.reshape(-1, 2))\n",
    "\n",
    "preds = np.apply_along_axis(lr_predict, 1, np.stack([gridXs, gridYs], axis=1)).ravel()\n",
    "#axis 1: apply across columns, i.e. row-wise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot\n",
    "plt.figure()\n",
    "plt.title(\"Predictions\")\n",
    "\n",
    "plt.scatter(gridXs, gridYs, 2, c=preds)\n",
    "#colors = [logReg.predict(np.array([a,b]).reshape(-1,2)) for a in xx for b in yy]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot\n",
    "plt.figure()\n",
    "plt.title(\"Predictions and Decision Boundary\")\n",
    "blueSet = y == 0\n",
    "orangeSet = y == 1\n",
    "\n",
    "plt.scatter(X[blueSet, 0], X[blueSet, 1], c=\"blue\",\n",
    "            s=20, edgecolor='k')\n",
    "plt.scatter(X[orangeSet, 0], X[orangeSet, 1], c=\"orange\",\n",
    "            s=20, edgecolor='k')\n",
    "plt.xlabel(\"$x_1$\")\n",
    "plt.ylabel(\"$x_2$\")\n",
    "# Print Decision Boundary\n",
    "plt.ylim(X[:,1].min(), X[:,1].max())\n",
    "plt.plot([X[:,0].min(), X[:,0].max()], y_boundary, 'r-')\n",
    "plt.scatter(gridXs, gridYs, 5, c=preds)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_predict_proba(k):\n",
    "    return logReg.predict_proba(k.reshape(-1, 2))[:,1]\n",
    "\n",
    "predProbs = np.apply_along_axis(lr_predict_proba, 1, np.stack([gridXs, gridYs], axis=1)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot\n",
    "plt.figure()\n",
    "plt.title(\"Color Map of Predicted Probability\")\n",
    "\n",
    "plt.xlabel(\"$x_1$\")\n",
    "plt.ylabel(\"$x_2$\")\n",
    "\n",
    "# Print Decision Boundary\n",
    "plt.ylim(X[:,1].min(), X[:,1].max())\n",
    "plt.plot([X[:,0].min(), X[:,0].max()], y_boundary, 'r-')\n",
    "\n",
    "# Print Probabilities\n",
    "plt.scatter(gridXs, gridYs, 200, c=predProbs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def svc_predict(k):\n",
    "    return svc.predict(k.reshape(-1, 2))\n",
    "\n",
    "svc_preds = np.apply_along_axis(svc_predict, 1, np.stack([gridXs, gridYs], axis=1)).ravel()\n",
    "\n",
    "\n",
    "# Scatter Plot\n",
    "plt.figure()\n",
    "plt.title(\"SVM-based Predictions, LR Decision Boundary\")\n",
    "blueSet = y == 0\n",
    "orangeSet = y == 1\n",
    "\n",
    "#plt.scatter(X[blueSet, 0], X[blueSet, 1], c=\"blue\",\n",
    "#            s=20, edgecolor='k')\n",
    "#plt.scatter(X[orangeSet, 0], X[orangeSet, 1], c=\"orange\",\n",
    "#            s=20, edgecolor='k')\n",
    "plt.xlabel(\"$x_1$\")\n",
    "plt.ylabel(\"$x_2$\")\n",
    "# Print Decision Boundary\n",
    "plt.ylim(X[:,1].min(), X[:,1].max())\n",
    "plt.plot([X[:,0].min(), X[:,0].max()], y_boundary, 'r-')\n",
    "plt.scatter(gridXs, gridYs, 5, c=svc_preds)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises:\n",
    "\n",
    "- What is the MSE (mean squared error) for KNN?\n",
    "- Is KNN a linear classifier?\n",
    "- What influence does the parameter $k$ have on bias and variance? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
